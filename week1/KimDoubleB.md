## 런타임 메모리 영역

<img width="790" height="450" alt="Image" src="https://github.com/user-attachments/assets/7d05134c-8ee1-4f21-a2c3-1814b24fb371" />

<br/>

Per Thread
- 프로그램 카운터 레지스터
    - 현재 실행 중인 바이트 코드 줄 번호 표시
    - "스레드가 지금 어디를 실행하고 있는가"를 아는 유일한 단서이기에 메모리 오류가 발생해서는 안됨. JVM 명세는 "적어도 프로그램 실행 위치는 절대 잃어버리지 않는다"는 것을 보장하기 위해, PC 레지스터를 OOM 발생 조건에서 의도적으로 제외.
- 자바 가상머신 스택
    - 스택 프레임을 만들어 지역 변수 테이블, 피연산자 스택, 동적 링크, 메서드 반환 값 등의 정보 저장
    - 해당 영역에서는 2가지 오류(StackOverflowError, OutOfMemoryError) 발생 가능
- 네이티브 메서드 스택
    - 자바 가상머신 스택과 비슷하나 네이티브 메서드를 실행할 때 이용
        - 네이티브 메서드란 C, C++ 같은 네이티브/원시 언어로 작성된 메서드를 의미 (`native` keyword)
    - JVM 명세에 어떤 구조로 구성해야하는지 정의되어 있지 않기에 자바 가상머신 스택과 합쳐놓은 가상 머신도 존재함

<br/>

힙
- ‘거의’ 모든 객체 인스턴스와 배열이 할당되는 공간
    - ‘거의’의 예외: ‘탈출 분석 기술(Escape Analysis)'을 통한 최적화
        - “이 객체는 이 메서드를 탈출하지 못한다” 확인 ⇒ `new` 로 만든 객체를 현재 메서드의 스택 프레임에 직접 할당
            - 메서드 종료 시, 스택 프레임 제거되며 객체 즉시 함께 제거
            - 가비지 컬렉션 대상에서 제외함으로 GC 오버헤드 감소
        - 스칼라 치환 ⇒ 객체를 구성하는 멤버 변수(필드)를 풀어 스택에 지역변수 처럼 저장
- 객체 할당 효율을 높이고자 스레드 로컬 할당 버퍼를 여러 개로 나눠 활용
    - 여러 스레드가 동시에 `new` 를 통해 객체를 생성 ⇒공유 자원에 객체 할당하려고 경쟁하게 됨
    - 이를 해결하려면 객체 할당 때마다 힙에 Lock을 걸어야 하는데, 이는 엄청난 오버헤드
    - TLAB(Thread-Local Allocation Buffers)를 통해 해결
        - 스레드 전용 버퍼 공간을 만들어둠
        - 스레드가 객체 생성 시, 자신에게 할당된 TLAB에 객체를 할당
        - Lock 필요 없고, TLAB에서 다음 빈 주소를 가리키는 포인터만 옮기는 액션만 하면 됨
        - TLAB이 꽉 차거나, TLAB보다 큰 객체 할당 필요 시, 힙 공용 공간에 접근/Lock해서 새로운 TLAB을 받아옴
- 물리적으로 떨어진 메모리에 위치해도 상관없으나 논리적으론 연속이 되어야 함

<br/>

메서드 영역
- 타입 정보, 상수, 정적 변수, JIT 컴파일러가 컴파일한 코드 캐시 등 저장
- Metaspace는 HotSpot JVM이 Method Area를 실제로 구현한 방식(implementation) 중 하나로, Java 8 이후 Method Area의 모든 역할을 Metaspace가 맡았습니다.
- 런타임 상수 풀
    - 클래스 버전, 필드, 메서드, 인터페이스 등 클래스 파일에 포함된 설명 정보, 컴파일 타임에 생성된 다양한 리터럴과 심벌 참조 저장
    - 런타임에도 상수 풀에 새로운 상수가 추가될 수 있음
        - 자바 언어에서는 상수가 꼭 컴파일 타임에 생성되어야 한다는 규칙은 없음
        - String.intern()

<br/>

다이렉트 메모리
- 가상 머신 런타임에 속하지 않으며, 정의된 영역도 아님. 즉, OS 레벨의 메모리 영역
    - 이 영역 한도는 `-XX:MaxDirectMemorySize` 등의 JVM 옵션으로 제한이 가능하지만, JVM 내부적으로 Heap/Stack/Method Area/Native Method Stack 등에 속하진 않음

<br/>

## 객체 들여다보기

객체 생성
- 상수 풀 안의 클래스를 가리키는 심벌 참조인지 확인
- 심벌 참조가 뜻하는 클래스가 로딩, 해석, 초기화 되었는지 확인
- 로딩이 완료되면 메모리를 할당
    - Java heap이 규칙적인가? ⇒ Bump the pointer, Free list
        - Compact, Sweep Algorithm
    - 가용 공간을 어떻게 나눌 것인가? ⇒ CAS, TLAB
- 할당받은 공간을 0으로 초기화
- 객체에 필요한 설정을 수행
    - 어떤 클래스의 인스턴스인지, 클래스의 메타정보 위치, 해시코드는 무엇인지 등
- 생성자 실행



<br/>

# 궁금증

<br/>

> “탈출 분석 기술이 날로 발전하면서 스택 할당과 스칼라 치환 최적화 방식이 살짝 달라졌다”라는 구문에서 ‘탈출 분석 기술’이 어떤 것을 의미해? 특정 객체 인스턴스는 힙에 저장되지 않는 것을 의미하는 기술인건가?

## 탈출 분석 (Escape Analysis) 기술의 의미

**탈출 분석(Escape Analysis)은 JVM의 JIT 컴파일러가 수행하는 고도의 최적화 기술로, "특정 객체가 힙(Heap)에 저장될 필요가 있는가?"를 분석**합니다.

여기서 '탈출(Escape)'이란, **한 객체가 자신이 선언된 메서드의 범위를 벗어나서도(즉, 밖에서도) 사용될 수 있는 상태**를 의미합니다.

- **탈출 O (Escape):**
    - 메서드의 반환 값(return)으로 객체가 나가는 경우
    - `static` 필드나 다른 객체의 인스턴스 필드에 저장되는 경우
    - 다른 스레드에서 접근 가능한 경우
    - ➡️ 이 경우, 객체는 여러 곳에서 참조되어야 하므로 **반드시 힙(Heap)에 생성**되어야 합니다.
- **탈출 X (No Escape):**
    - 객체가 메서드 안에서만 생성되고, 사용되고, 메서드가 끝나면 아무도 그 객체를 참조하지 않는 경우. (즉, 메서드 내부에서만 쓰이는 로컬 변수)
    - ➡️ **이것이 최적화 대상입니다!**

### 💡 탈출 분석을 통한 최적화 (스택 할당과 스칼라 치환)

JIT 컴파일러가 "이 객체는 절대 이 메서드를 탈출하지 못한다"고 판단하면, 다음과 같은 최적화를 수행합니다.

### 1. 스택 할당 (Stack Allocation)

- **동작:** `new` 키워드로 생성된 객체를 비싼 **힙(Heap)이 아닌, 현재 메서드의 스택 프레임**에 직접 할당합니다.
- **장점:**
    - 메서드가 종료되면 스택 프레임이 제거되면서 객체도 **즉시 함께 제거**됩니다.
    - 비용이 많이 드는 **가비지 컬렉션(GC)의 대상이 되지 않습니다.** (GC 오버헤드 감소)

### 2. 스칼라 치환 (Scalar Replacement)

- *'스칼라(Scalar)'**란? `int`, `long`처럼 더 이상 쪼갤 수 없는 기본 데이터 타입을 의미합니다. (반대는 `Object`처럼 여러 필드로 구성된 'Aggregate')
- **동작:** 스택 할당보다 한 단계 더 나아간 최적화입니다. 객체 자체를 스택에 할당하는 것조차 하지 않고, 그 **객체를 구성하는 멤버 변수(필드)들만 '풀어서'** 스택에 **지역 변수처럼** 저장합니다.

<br/>

<br/>

> JDK에서 Template interpreter와 Bytecode Interpreter에 대해 설명해줘

JVM이 Java 바이트코드를 실행하는 첫 번째 단계는 **인터프리터(Interpreter)**를 통하는 것입니다. 인터프리터는 기계어(Native Code)로 컴파일된 것이 아니라, 바이트코드를 한 줄씩 읽어서 해석하고 실행합니다.

HotSpot JVM은 역사적으로 두 가지 방식의 인터프리터를 사용했습니다.

### Bytecode Interpreter (고전 방식)

- **동작:** 거대한 `while` 루프 안에 `switch` 문이 있는 구조로 동작합니다.
- **메커니즘:**
    1. `while (true)`: 루프를 돕니다.
    2. `opcode = readBytecode();`: 다음 바이트코드(예: `ILOAD_1`)를 하나 읽습니다.
    3. `switch (opcode)`: 읽은 바이트코드가 무엇인지 `switch` 문으로 분기합니다.
    4. `case ILOAD_1:`: 해당 바이트코드에 정의된 C++ 함수(예: '로컬 변수 1번을 스택에 올려라')를 실행합니다.
    5. 다시 `while` 루프의 처음으로 돌아가 다음 바이트코드를 읽습니다.
- **단점:** 매 바이트코드를 실행할 때마다 '루프 돌기 -> 바이트코드 읽기 -> `switch`문으로 분기하기'라는 **디스패치 오버헤드(Dispatch Overhead)**가 발생하여 속도가 매우 느립니다.

### Template Interpreter (현재 HotSpot 방식)

- **동작:** `switch` 문을 제거하고, 각 바이트코드에 대한 **기계어 '템플릿(Template)'**을 미리 만들어두고 점프하는 방식입니다.
- **메커니즘:**
    1. JVM 시작 시, 각 바이트코드(`ILOAD_1`, `IADD` 등)를 실행하는 **짧은 네이티브 기계어 조각(템플릿)**들을 미리 생성합니다.
    2. 각 템플릿의 *마지막*에는 "다음 바이트코드를 읽고, 그 바이트코드에 해당하는 템플릿의 주소로 바로 **점프(jump)**하라"는 기계어가 포함됩니다.
    3. 실행 시, `ILOAD_1` 템플릿(기계어)이 실행된 후, `switch` 문을 거치지 않고 바로 다음 바이트코드(예: `IADD`)의 템플릿(기계어)으로 점프하여 실행을 이어갑니다.
- **장점:** `switch` 문을 사용한 분기(디스패치 오버헤드)가 사라지고, 실행 흐름이 네이티브 기계어 템플릿 사이를 직접 이동하므로 Bytecode Interpreter보다 훨씬 빠릅니다.

JIT 컴파일러가 작동하기 전까지는 이 **Template Interpreter**가 코드를 실행합니다.

<br/>

<br/>

> `+XX:CompactFields` VM 옵션을 이용하면 하위 클래스의 필드 중 길이가 짧은 것들은 상위 클래스의 변수 사이 사이에 끼워 넣어져서 “공간이 조금이나마 절약”된다. 이 때 어떻게 “공간이 절약”되는거야? 그 메커니즘과 메모리 구성을 엮어 설명해줘.
 

## `+XX:CompactFields`와 공간 절약 메커니즘

이 옵션을 이해하려면 먼저 **메모리 패딩(Memory Padding)** 개념을 알아야 합니다.

### 📦 객체 메모리 레이아웃과 패딩

1. **객체 구성:** Java 객체는 힙에 저장될 때 **[객체 헤더(Header)] + [인스턴스 필드(Fields)]**로 구성됩니다.
2. **메모리 정렬 (Alignment):** CPU는 메모리를 8바이트(64비트 기준) 단위로 묶어서 읽을 때 가장 효율적입니다. 이 때문에 JVM은 모든 객체의 시작 주소와 총 크기를 **8의 배수**로 맞춥니다.
3. **패딩 (Padding):** 객체의 [헤더] + [필드] 크기가 8의 배수가 아닐 경우 (예: 21바이트), JVM은 객체 끝에 아무 의미 없는 **빈 공간(패딩)**을 3바이트 추가하여 총 24바이트(8의 배수)로 만듭니다.

### ⚙️ `+XX:CompactFields`의 작동 원리

이 옵션이 없을 때(기본값), JVM은 상속 관계에서 필드를 배치할 때 **부모 클래스의 필드를 먼저** 놓고, 그 뒤에 **자식 클래스의 필드**를 놓습니다.

- **문제 상황 (Default):**`class Parent { long p1; byte p2; }` (p1: 8바이트, p2: 1바이트)
`class Child extends Parent { long c1; byte c2; }` (c1: 8바이트, c2: 1바이트)
    
    `Child` 객체의 기본 메모리 레이아웃은 (단순화된 예시):
    
    1. 객체 헤더 (12 bytes)
    2. `p1` (8 bytes)
    3. `p2` (1 byte)
    4. **내부 패딩 (7 bytes):** `p2` (1바이트) 뒤에 7바이트의 빈 공간이 생깁니다. 왜냐하면 다음 필드인 `c1`(long)이 8바이트 정렬 주소에서 시작해야 하기 때문입니다.
    5. `c1` (8 bytes)
    6. `c2` (1 byte)
    7. **최종 패딩 (7 bytes):** 객체 전체 크기를 8의 배수(48바이트)로 맞추기 위해 7바이트가 추가됩니다.
    - *총 낭비 공간 = 7 (내부) + 7 (최종) = 14바이트*
- **`+XX:CompactFields` 적용 시:**
이 옵션은 "부모-자식 순서 규칙을 깨고, **필드 타입**을 기준으로 재배열하여 **내부 패딩을 최소화**하라"는 명령입니다.
    1. JVM은 `Child` 객체 레이아웃을 정할 때 `Parent`와 `Child`의 필드를 모두 모읍니다.
    2. 타입 크기순으로 재배열합니다: (long 2개, byte 2개)
    3. `Child` 객체의 **압축된** 레이아웃:
        1. 객체 헤더 (12 bytes)
        2. `p1` (8 bytes)
        3. `c1` (8 bytes) ⬅️ **자식 클래스의 `long`이 "끼워 넣어짐"**
        4. `p2` (1 byte)
        5. `c2` (1 byte) ⬅️ **자식 클래스의 `byte`가 "끼워 넣어짐"**
        6. **최종 패딩 (2 bytes):** 총 30바이트(12+8+8+1+1)이므로 8의 배수(32바이트)를 맞추기 위한 패딩이 2바이트만 필요합니다. ( *실제로는 12+16+2=30이므로 2바이트 패딩 -> 32바이트가 됨. 또는 8바이트 경계에 따라 6바이트 패딩 -> 40바이트가 될 수 있음. 중요한 것은 내부 패딩이 사라진다는 것* )

**결론:** "공간이 절약"된다는 것은, 부모와 자식 필드 사이에 발생하던 **'내부 패딩(Internal Padding)'** 공간에 하위 클래스의 작은 필드들을 "끼워 넣어" 객체 중간의 빈 공간을 제거함으로써 객체의 총 크기를 줄이는 것을 의미합니다.